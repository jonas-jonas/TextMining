{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Spacy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data and load word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The venue was great\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "comments = pd.read_csv('data/comments_top500.csv')\n",
    "\n",
    "test_comment = \"The venue was great\"#comments.iloc[120].body.replace(u'\\n', '')\n",
    "\n",
    "print(test_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lexicon():\n",
    "    lexicon = []\n",
    "    with open('data/sentiments/subjectivity.ttf') as file:\n",
    "        for line in file.readlines():\n",
    "            # Aufbau des Lexicons: type=strongsubj len=1 word1=hamper pos1=verb stemmed1=y priorpolarity=negative\n",
    "            word_entry = {}\n",
    "            for entry in line.split(\" \"):\n",
    "                s = entry.split(\"=\")\n",
    "                if len(s) == 2:\n",
    "                    word_entry[s[0]] = s[1].replace(u'\\n', '')\n",
    "            lexicon.append(word_entry)\n",
    "\n",
    "    return pd.DataFrame(lexicon)\n",
    "\n",
    "lexicon = load_lexicon()\n",
    "\n",
    "lexicon_doc = nlp(' '.join(lexicon[\"word1\"].drop_duplicates()))\n",
    "# Get negatives: lexicon[lexicon[\"priorpolarity\"] == \"negative\"]\n",
    "# print(lexicon[lexicon[\"priorpolarity\"] == \"negative\"][\"word1\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_wordlist(input):\n",
    "    doc = nlp(input)\n",
    "    return [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_sentences(input):\n",
    "    doc = nlp(input.strip())\n",
    "    sentences = []\n",
    "    for sent in doc.sents:\n",
    "        sentences.append(review_wordlist(sent.text))\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, word_list):\n",
    "    queries = [(w, word.similarity(w)) for w in word_list if w.is_lower == word.is_lower and w.prob >= -15 and w.vector_norm]\n",
    "    by_similarity = sorted(queries, key=lambda w: w[1], reverse=True)\n",
    "    return by_similarity[:10]\n",
    "\n",
    "#print([w.lower_ for w in most_similar(nlp(u'bad')[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: How to handle words that have multiple polarities (example: food)\n",
    "def get_polarity(word):\n",
    "    word_series = lexicon[lexicon[\"word1\"] == word1]\n",
    "    polarity = word_series['priorpolarity'].drop_duplicates()\n",
    "    print(polarity)\n",
    "    return polarity.item()\n",
    "    \n",
    "\n",
    "\n",
    "#print(get_polarity('food'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4284    positive\n",
      "4285     neutral\n",
      "Name: priorpolarity, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "can only convert an array of size 1 to a Python scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-e34a25f0036f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mword1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mpolarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_polarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpolarity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-189-d11ea06fed78>\u001b[0m in \u001b[0;36mget_polarity\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpolarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'priorpolarity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/text_mining/env/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36mitem\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \"\"\"\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# copy numpy's message here because Py26 raises an IndexError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: can only convert an array of size 1 to a Python scalar"
     ]
    }
   ],
   "source": [
    "sentences = review_sentences(test_comment)\n",
    "\n",
    "for sent in sentences:\n",
    "    \n",
    "    result = {}\n",
    "    for word in nlp(' '.join(sent)):\n",
    "        x = most_similar(word, lexicon_doc)\n",
    "        for res in x:\n",
    "            word1 = res[0].text\n",
    "            polarity = get_polarity(word1)\n",
    "            if polarity in result:\n",
    "                result[polarity]['count'] +=1\n",
    "                result[polarity]['sim'] +=res[1]\n",
    "            else:\n",
    "                result[polarity] = {'count': 1, 'sim': res[1]}\n",
    "                \n",
    "    print(sent, [(sentiment, res['sim']/res['count']) for sentiment, res in result.items()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
